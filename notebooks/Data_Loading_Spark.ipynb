{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "# create sparksession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"insight\") \\\n",
    "    .getOrCreate()\n",
    "acquis = spark.read.option(\"inferSchema\", \"true\").option(\"header\", False).option(\"dateFormat\", \"yyyyMMdd\").option(\"delimiter\",\"|\").csv(\"../realdata/2010Q1/Acquisition_2010Q1.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = spark.read.option(\"inferSchema\", \"true\").option(\"header\", False).option(\"dateFormat\", \"yyyyMMdd\").option(\"delimiter\",\"|\").csv(\"../realdata/2010Q1/Performance_2010Q1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_aquisition = ['loanID', 'originationChannel', 'sellerName', 'origIntRate', 'origUPB', \n",
    "                       'origLoanTerm', 'originationDate', 'firstPaymentDate', 'LTV', 'CLTV', \n",
    "                        'numOfBorrowers', 'origDebtToIncomeRatio', 'borrowerCredScoreAtOrigination',\n",
    "                       'firstTimeBuyerIndicator', 'loanPurpose', 'propertyType', 'numOfUnits',\n",
    "                       'occupancyType', 'propertyState', 'zipCodeShort', 'primaryMortgInsurPercent', \n",
    "                       'productType', 'coborrowerCreditScoreAtOrig', 'mortgageInsurType', \n",
    "                       'relocationMortgIndicator']\n",
    "col_names_performance =['loanID', 'monthlyReportingPeriod', 'servicerName', 'currentIntRate',\n",
    "                       'currentActualUPB', 'loanAge', 'remMonthsToLegalMaturity', 'adjMonthToMaturity',\n",
    "                       'maturityDate', 'MSA', 'currentLoanDelinqStatus', 'modifFlag', 'zeroBalanceCode',\n",
    "                       'zeroBalanceEffectiveDate', 'lastPaidInstallDate', 'foreclosureDate',\n",
    "                       'dispositionDate', 'foreclosureCost', 'propPreservAndReparCosts', 'assetRecoveryCosts',\n",
    "                       'miscelHoldingExpensesAndCredits', 'associatedTaxesForHoldingProperty', 'netSaleProceeds',\n",
    "                       'creditEnhacementProceeds', 'repurchaseMakeWholeProceeds','otherForeclosureProceeds',\n",
    "                       'nonInterestBearingUPB', 'principalForegivenessAmount', 'repurchaseMakeWholeProceedsFlag',\n",
    "                       'foreclosurePrincipWriteOffAmont', 'servicingActivityIndicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "acquis_rn = acquis\n",
    "for colname in col_names_aquisition:\n",
    "    acquis_rn = acquis_rn.withColumnRenamed(\"_c\"+str(i),col_names_aquisition[i])\n",
    "    i = i + 1\n",
    "    \n",
    "i = 0\n",
    "perf_rn = perf\n",
    "for colname in col_names_performance:\n",
    "    perf_rn = perf_rn.withColumnRenamed(\"_c\"+str(i),col_names_performance[i])\n",
    "    i = i + 1\n",
    "#acquis_rn.select(acquis_rn.columns[:7]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.types import IntegerType\n",
    "perf_rn = perf_rn.withColumn(\"monthlyReportingPeriod\",to_date(perf_rn.monthlyReportingPeriod,'MM/dd/yyyy'))\n",
    "perf_rn = perf_rn.withColumn(\"currentLoanDelinqStatus\", perf_rn[\"currentLoanDelinqStatus\"].cast(IntegerType()))\n",
    "acquis_rn = acquis_rn.withColumn(\"originationDate\",to_date(acquis_rn.originationDate,'MM/yyyy'))\n",
    "acquis_rn = acquis_rn.withColumn(\"firstPaymentDate\",to_date(acquis_rn.firstPaymentDate,'MM/yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquis_rn.select(acquis_rn.columns[0:8]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((acquis_rn.count(), len(acquis_rn.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_rn.count(),len(perf_rn.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perf_rn.select(perf_rn.columns[:7]).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_rn.createOrReplaceTempView('perf')\n",
    "_2010Q1_perf = spark.sql(\n",
    "'''\n",
    "SELECT \n",
    "perf.loanID, perf.monthlyReportingPeriod, perf.loanAge, perf.currentLoanDelinqStatus FROM perf \n",
    "\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2010Q1_perf.select(_2010Q1_perf.columns[0:3]).show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_perf =_2010Q1_perf.groupBy(\"loanID\").pivot(\"monthlyReportingPeriod\").max(\"currentLoanDelinqStatus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_perf = pivot_perf.select(pivot_perf.columns[0:28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquis_rn.createOrReplaceTempView('acquis')\n",
    "sql_acquis = spark.sql(\n",
    "'''\n",
    "SELECT acquis.loanID, acquis.origIntRate, acquis.origUPB, acquis.originationDate, \n",
    "acquis.firstPaymentDate, acquis.LTV, acquis.CLTV, acquis.numOfBorrowers, acquis.origDebtToIncomeRatio, \n",
    "acquis.borrowerCredScoreAtOrigination, acquis.zipCodeShort, acquis.primaryMortgInsurPercent\n",
    "FROM acquis WHERE (originationDate BETWEEN '2010-01-01'AND '2010-12-01')\n",
    "\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_acquis.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_2010Q1 = sql_acquis.join(final_perf,on=['loanID'],how='inner')\n",
    "#print((_2010Q1.count(), len(_2010Q1.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2010Q1.select(_2010Q1.columns[0:9]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2010Q1.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2010Q1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import greatest\n",
    "clist = _2010Q1.columns[-14:]\n",
    "_2010Q1 = _2010Q1.withColumn(\"default_status\",greatest(*clist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|default_status| count|\n",
      "+--------------+------+\n",
      "|          null| 15412|\n",
      "|             0|147998|\n",
      "|             1|  3494|\n",
      "|             2|   359|\n",
      "|             3|   123|\n",
      "|             4|    98|\n",
      "|             5|    67|\n",
      "+--------------+------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_2010Q1.groupBy(\"default_status\").count().sort(\"default_status\").show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2010Q1 = _2010Q1.orderBy([\"loanID\",\"originationDate\",\"monthlyReportingPeriod\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_2010Q1.count(), len(_2010Q1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=perf_rn.agg({\"monthlyReportingPeriod\":\"max\"}).collect()[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perf_rn.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=perf_rn.agg({\"monthlyReportingPeriod\":\"min\"}).collect()[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
